name: integration-test

permissions:
  contents: read

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

on:
  workflow_dispatch: { }
  pull_request:
    paths:
      - 'apps/agentstack-server/**'
      - 'apps/agentstack-cli/**'
  push:
    branches:
      - main
    paths:
      - 'apps/agentstack-server/**'
      - 'apps/agentstack-cli/**'
jobs:
  integration-test:
    timeout-minutes: 25
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6
      - name: Maximize build space
        uses: ./.github/actions/maximize-build-space
        with:
          root-reserve-mb: 15360
          temp-reserve-mb: 2048
          swap-size-mb: 1024
          remove-dotnet: 'true'
      - name: "Set up Lima"
        uses: lima-vm/lima-actions/setup@v1
        id: lima-actions-setup
      - name: "Cache ~/.cache/lima"
        uses: actions/cache@v5
        with:
          path: ~/.cache/lima
          key: lima-${{ steps.lima-actions-setup.outputs.version }}
      - uses: actions/checkout@v6
      - uses: ./.github/actions/setup
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      - run: mise run agentstack-server:test:integration
        env:
          LLM_API_BASE: "${{ secrets.OPENAI_API_BASE }}"
          LLM_MODEL: "${{ vars.OPENAI_MODEL }}"
          LLM_API_KEY: "${{ secrets.OPENAI_API_KEY }}"
          # LLM_API_BASE: "https://api.groq.com/openai/v1"
          # LLM_MODEL: "groq:meta-llama/llama-4-maverick-17b-128e-instruct"
          # LLM_API_KEY: "${{ secrets.GROQ_API_KEY }}"
      - run: uv cache prune --ci
