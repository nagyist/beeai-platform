name: e2e-test

permissions:
  contents: read

on:
  workflow_dispatch: { }
  pull_request:
    paths:
      - 'apps/beeai-server/**'
      - 'apps/beeai-cli/**'
      - 'helm/**'
  push:
    branches:
      - main
    paths:
      - 'apps/beeai-server/**'
      - 'apps/beeai-cli/**'
      - 'helm/**'
jobs:
  e2e-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: "Set up Lima"
        uses: lima-vm/lima-actions/setup@v1
        id: lima-actions-setup
      - name: "Cache ~/.cache/lima"
        uses: actions/cache@v4
        with:
          path: ~/.cache/lima
          key: lima-${{ steps.lima-actions-setup.outputs.version }}
      - uses: ./.github/actions/setup
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      - run: mise run beeai-server:test:e2e
        env:
          # TODO: use github models
          # LLM_API_BASE: "https://models.github.ai/inference"
          # LLM_MODEL: "meta/Meta-Llama-3.1-8B-Instruct"
          # LLM_API_KEY: "${{ secrets.GITHUB_TOKEN }}"
          # TODO: groq is not working with chat agent
          LLM_API_BASE: "https://api.groq.com/openai/v1"
          LLM_MODEL: "groq:meta-llama/llama-4-maverick-17b-128e-instruct"
          LLM_API_KEY: "${{ secrets.GROQ_API_KEY }}"
